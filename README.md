# Presentation Understanding Engine

An AI-powered system that performs **semantic understanding of PowerPoint presentations** to automatically generate:
- ğŸ™ï¸ Teacher-style narrated video lectures
- ğŸ“ Structured multiple-choice assessments (MCQs)
- ğŸ¬ Professional video output with TTS narration

Designed for **EdTech**, **training automation**, and **instructional content pipelines**.

---

## âœ¨ Features

- **Smart Parsing**: Robust slide text extraction (handles empty or image-only slides)
- **AI Narration**: LLM-generated teacher-style explanations (not verbatim repetition)
- **Video Generation**: Automatic video lectures with TTS and slide images
- **Quiz Generation**: MCQs with difficulty levels in strict JSON format
- **Multilingual**: English, French, and Hindi support
- **Real-time Progress**: WebSocket-based live updates during processing
- **Modern UI**: Next.js frontend with beautiful Tailwind CSS design
- **Docker Ready**: Production-ready containerized deployment

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (Next.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Upload  â”‚  â”‚ Processing  â”‚  â”‚   Results    â”‚  â”‚   Quiz    â”‚  â”‚
â”‚  â”‚  Page   â”‚  â”‚    Page     â”‚  â”‚    Page      â”‚  â”‚   Mode    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚                â”‚
        â–¼              â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  REST API   â”‚  â”‚  WebSocket   â”‚  â”‚    Job Manager          â”‚ â”‚
â”‚  â”‚  Endpoints  â”‚  â”‚   Handler    â”‚  â”‚  (Async Processing)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                      â”‚
          â–¼                â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Processing Pipeline                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   PPT     â”‚  â”‚ Narration â”‚  â”‚    TTS    â”‚  â”‚    Video     â”‚  â”‚
â”‚  â”‚  Parser   â”‚â†’ â”‚   Chain   â”‚â†’ â”‚  Service  â”‚â†’ â”‚  Assembler   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â†“                                           â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚               â”‚   MCQ     â”‚                                      â”‚
â”‚               â”‚   Chain   â”‚                                      â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Ollama LLM                               â”‚
â”‚                    (llama3.1:8b or similar)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.11+**
- **FastAPI** - High-performance API framework
- **LangChain** - LLM orchestration
- **Ollama** - Local LLM inference
- **python-pptx** - PowerPoint parsing
- **edge-tts** - Microsoft neural TTS
- **FFmpeg** - Video processing
- **Pillow** - Image processing

### Frontend
- **Next.js 14** - React framework with App Router
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first styling
- **shadcn/ui** - Beautiful component library
- **React Query** - Server state management
- **Framer Motion** - Animations

### DevOps
- **Docker & Docker Compose** - Containerization
- **Nginx** - Reverse proxy
- **GitHub Actions** - CI/CD (optional)

---

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/Daivik2605/presentation-understanding-engine.git
cd presentation-understanding-engine

# Start with Docker Compose
docker-compose up -d

# Pull the LLM model (first time only)
docker exec -it ppt-engine-ollama ollama pull llama3.1:8b
```

The application will be available at:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

### Option 2: Local Development

#### Prerequisites
- Python 3.11+
- Node.js 18+
- FFmpeg
- Ollama

#### Backend Setup

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate
# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Copy environment file
copy .env.example .env  # Windows
cp .env.example .env    # Linux/Mac

# Start Ollama and pull model
ollama serve
ollama pull llama3.1:8b

# Run the backend
uvicorn app.main:app --reload
```

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Copy environment file
copy .env.example .env.local  # Windows
cp .env.example .env.local    # Linux/Mac

# Run the frontend
npm run dev
```

---

## ğŸ“ Project Structure

```
presentation-understanding-engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ health.py          # Health check endpoint
â”‚   â”‚   â”œâ”€â”€ process.py         # Upload & processing endpoint
â”‚   â”‚   â”œâ”€â”€ jobs.py            # Job management endpoints
â”‚   â”‚   â””â”€â”€ websocket.py       # WebSocket for progress updates
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Pydantic settings
â”‚   â”‚   â”œâ”€â”€ logging.py         # Structured logging
â”‚   â”‚   â””â”€â”€ exceptions.py      # Custom exceptions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ job.py             # Job & progress models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ppt_parser.py      # PowerPoint extraction
â”‚   â”‚   â”œâ”€â”€ narration_chain.py # LLM narration generation
â”‚   â”‚   â”œâ”€â”€ qa_chain.py        # LLM MCQ generation
â”‚   â”‚   â”œâ”€â”€ tts_service.py     # Text-to-speech
â”‚   â”‚   â”œâ”€â”€ slide_renderer.py  # Slide image rendering
â”‚   â”‚   â”œâ”€â”€ video_assembler.py # Individual slide videos
â”‚   â”‚   â”œâ”€â”€ video_stitcher.py  # Final video assembly
â”‚   â”‚   â”œâ”€â”€ job_manager.py     # Job tracking
â”‚   â”‚   â””â”€â”€ async_processor.py # Async processing pipeline
â”‚   â””â”€â”€ main.py                # FastAPI application
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Home page
â”‚   â”‚   â”œâ”€â”€ upload/            # Upload page
â”‚   â”‚   â”œâ”€â”€ processing/        # Processing progress page
â”‚   â”‚   â””â”€â”€ results/           # Results display page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/                # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ upload/            # Upload components
â”‚   â”‚   â”œâ”€â”€ processing/        # Progress components
â”‚   â”‚   â””â”€â”€ results/           # Result components
â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks
â”‚   â””â”€â”€ lib/                   # Utilities & API client
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ uploads/               # Uploaded files
â”‚   â”œâ”€â”€ outputs/               # Generated outputs
â”‚   â””â”€â”€ temp/                  # Temporary files
â”œâ”€â”€ docker-compose.yml         # Production Docker setup
â”œâ”€â”€ docker-compose.dev.yml     # Development Docker setup
â”œâ”€â”€ Dockerfile                 # Backend container
â”œâ”€â”€ nginx.conf                 # Nginx configuration
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸ”§ Configuration

### Backend Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama server URL |
| `OLLAMA_MODEL` | `llama3.1:8b` | LLM model to use |
| `TTS_VOICE_EN` | `en-US-AriaNeural` | English TTS voice |
| `TTS_VOICE_FR` | `fr-FR-DeniseNeural` | French TTS voice |
| `TTS_VOICE_HI` | `hi-IN-SwaraNeural` | Hindi TTS voice |
| `VIDEO_FPS` | `1` | Video frames per second |
| `VIDEO_RESOLUTION` | `1920x1080` | Video resolution |
| `MAX_SLIDES` | `20` | Maximum slides to process |
| `MAX_FILE_SIZE_MB` | `50` | Maximum upload file size |
| `LOG_LEVEL` | `INFO` | Logging level |
| `ENVIRONMENT` | `development` | Environment mode |

### Frontend Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `NEXT_PUBLIC_API_URL` | `http://localhost:8000` | Backend API URL |

---

## ğŸ“– API Documentation

### REST Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/process` | Upload and process PPT |
| `GET` | `/api/v1/jobs/{job_id}/status` | Get job status |
| `GET` | `/api/v1/jobs/{job_id}/result` | Get job result |
| `POST` | `/api/v1/jobs/{job_id}/cancel` | Cancel job |
| `GET` | `/api/v1/jobs` | List all jobs |
| `GET` | `/api/v1/health` | Health check |

### WebSocket

Connect to `/ws/jobs/{job_id}` for real-time progress updates.

### Example Usage

```python
import requests

# Upload a presentation
with open("presentation.pptx", "rb") as f:
    response = requests.post(
        "http://localhost:8000/api/v1/process",
        files={"file": f},
        data={
            "language": "en",
            "max_slides": 10,
            "generate_video": True,
            "generate_mcqs": True
        }
    )

job_id = response.json()["job_id"]

# Check status
status = requests.get(f"http://localhost:8000/api/v1/jobs/{job_id}/status")
print(status.json())

# Get results when complete
result = requests.get(f"http://localhost:8000/api/v1/jobs/{job_id}/result")
print(result.json())
```

---

## ğŸ¨ Screenshots

### Home Page
Modern landing page with feature highlights and call-to-action.

### Upload Page
Drag & drop interface with language selection and processing options.

### Processing Page
Real-time progress tracking with WebSocket updates for each slide.

### Results Page
- **Slides Tab**: Browse slides with narration and audio playback
- **Video Tab**: Watch the complete video lecture
- **Quiz Tab**: Interactive MCQ quiz mode with scoring
- **Export Tab**: Download all generated content

---

## ğŸ§ª Testing

```bash
# Run backend tests
pytest

# Run with coverage
pytest --cov=app

# Run frontend tests
cd frontend
npm test
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) for LLM orchestration
- [Ollama](https://ollama.ai/) for local LLM inference
- [shadcn/ui](https://ui.shadcn.com/) for beautiful components
- [Microsoft Edge TTS](https://github.com/rany2/edge-tts) for neural voices

